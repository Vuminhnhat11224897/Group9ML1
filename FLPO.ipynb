{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sử dụng với dữ liệu creditcard https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud?resource=download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard.csv')\n",
    "def create_datastream(data, batch_size):\n",
    "    datastream = []\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        batch = data.iloc[i:i+batch_size]\n",
    "        datastream.append(batch)\n",
    "    return datastream\n",
    "batch_size = 100\n",
    "S = create_datastream(df, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest_classifier(X, y, n_estimators=10):\n",
    "    \"\"\"\n",
    "    Huấn luyện bộ phân loại Random forest trên dữ liệu X, y.\n",
    "    n_estimators: Số lượng cây trong Random forest.\n",
    "    \"\"\"\n",
    "    rf = RandomForestClassifier(n_estimators=n_estimators)\n",
    "    rf.fit(X, y)\n",
    "    return rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_ensemble_size(C, sample, unique_label, anpha, min_num = 3):\n",
    "    \"\"\"\n",
    "    Cơ chế adaptive_esemble \n",
    "    C : Bộ phân loại yếu\n",
    "    sample\n",
    "    unique_label : Tập hợp nhãn trong luồng dữ liệu\n",
    "    anpha : hyper parameter\n",
    "    min_num : số lượng C tối thiểu \n",
    "    \"\"\"\n",
    "    probability_list = []\n",
    "    for i in range(len(unique_label)):\n",
    "        li = [] \n",
    "        for j in range(len(C)):\n",
    "            probabilities = C[0].predict_proba(sample)[0]\n",
    "            probability_dict = {label: prob for label, prob in zip(C[0].classes_, probabilities)}\n",
    "            latest_proba = probability_dict.get(unique_label[i], 0)\n",
    "            probabilities1 = C[j].predict_proba(sample)[0]\n",
    "            probability_dict1 = {label: prob for label, prob in zip(C[j].classes_, probabilities1)}\n",
    "            current_proba = probability_dict1.get(unique_label[i], 0)\n",
    "            if len(li) < min_num:\n",
    "                li.append(current_proba)\n",
    "            else:\n",
    "                if abs(current_proba - latest_proba) < anpha :\n",
    "                    li.append(current_proba)\n",
    "                else: \n",
    "                    break   \n",
    "        probability_list.append(li)     \n",
    "    return probability_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(x, y):\n",
    "    \"\"\"Tính hồi quy tuyến tính\"\"\"\n",
    "    A = np.vstack([x, np.ones(len(x))]).T\n",
    "    m, c = np.linalg.lstsq(A, y, rcond=None)[0]\n",
    "    return m, c\n",
    "\n",
    "def tendency_prediction(probability_list, Y, epsilon=0.01):\n",
    "    \"\"\"\n",
    "    Thực hiện cơ chế dự đoán xu hướng\n",
    "    Input:\n",
    "    - probability_list: Danh sách xác suất cho mỗi mẫu\n",
    "    - Y: Danh sách các lớp trong luồng dữ liệu\n",
    "    - epsilon: Hệ số trọng số (mặc định là 0.01)\n",
    "    Output:\n",
    "    - Ps: Lớp dự đoán cho mẫu\n",
    "    \"\"\"\n",
    "    predicted_probabilities = []\n",
    "    for i in range(len(Y)):\n",
    "        li = probability_list[i]\n",
    "        x = np.arange(1, len(li) + 1)\n",
    "        y = np.array(li)\n",
    "        slope, intercept = linear_regression(x, y)\n",
    "        next_value = slope * (len(li) + 1) + intercept\n",
    "        li.append(next_value)\n",
    "        weighted_prob = sum([li[x] * (1 + x * epsilon) for x in range(len(li))]) / len(li)\n",
    "        predicted_probabilities.append(weighted_prob)\n",
    "    Ps = Y[np.argmax(predicted_probabilities)]\n",
    "    \n",
    "    return Ps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m unique_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     32\u001b[0m unique_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(unique_labels)\n\u001b[1;32m---> 33\u001b[0m C, pre \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_data_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munique_labels\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 24\u001b[0m, in \u001b[0;36mprocess_data_stream\u001b[1;34m(S, m, k, unique_labels)\u001b[0m\n\u001b[0;32m     22\u001b[0m sample \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([row[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]], columns\u001b[38;5;241m=\u001b[39mBi\u001b[38;5;241m.\u001b[39mcolumns[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     23\u001b[0m anpha \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1500\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(Bi)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.2\u001b[39m\n\u001b[1;32m---> 24\u001b[0m selected_classifiers \u001b[38;5;241m=\u001b[39m \u001b[43madaptive_ensemble_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munique_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m pre_sample \u001b[38;5;241m=\u001b[39m tendency_prediction(selected_classifiers, unique_labels)\n\u001b[0;32m     26\u001b[0m block_predictions\u001b[38;5;241m.\u001b[39mappend(pre_sample)\n",
      "Cell \u001b[1;32mIn[4], line 6\u001b[0m, in \u001b[0;36madaptive_ensemble_size\u001b[1;34m(C, sample, unique_label, anpha, min_num)\u001b[0m\n\u001b[0;32m      4\u001b[0m li \u001b[38;5;241m=\u001b[39m [] \n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(C)):\n\u001b[1;32m----> 6\u001b[0m     probabilities \u001b[38;5;241m=\u001b[39m \u001b[43mC\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      7\u001b[0m     probability_dict \u001b[38;5;241m=\u001b[39m {label: prob \u001b[38;5;28;01mfor\u001b[39;00m label, prob \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(C[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mclasses_, probabilities)}\n\u001b[0;32m      8\u001b[0m     latest_proba \u001b[38;5;241m=\u001b[39m probability_dict\u001b[38;5;241m.\u001b[39mget(unique_label[i], \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\MyPC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:876\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    871\u001b[0m all_proba \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    872\u001b[0m     np\u001b[38;5;241m.\u001b[39mzeros((X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], j), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39matleast_1d(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_)\n\u001b[0;32m    874\u001b[0m ]\n\u001b[0;32m    875\u001b[0m lock \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mLock()\n\u001b[1;32m--> 876\u001b[0m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequire\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msharedmem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_accumulate_prediction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_proba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimators_\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m proba \u001b[38;5;129;01min\u001b[39;00m all_proba:\n\u001b[0;32m    882\u001b[0m     proba \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_)\n",
      "File \u001b[1;32mc:\\Users\\MyPC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MyPC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\MyPC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\MyPC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\MyPC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:647\u001b[0m, in \u001b[0;36m_accumulate_prediction\u001b[1;34m(predict, X, out, lock)\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_accumulate_prediction\u001b[39m(predict, X, out, lock):\n\u001b[0;32m    641\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;124;03m    This is a utility function for joblib's Parallel.\u001b[39;00m\n\u001b[0;32m    643\u001b[0m \n\u001b[0;32m    644\u001b[0m \u001b[38;5;124;03m    It can't go locally in ForestClassifier or ForestRegressor, because joblib\u001b[39;00m\n\u001b[0;32m    645\u001b[0m \u001b[38;5;124;03m    complains that it cannot pickle it when placed there.\u001b[39;00m\n\u001b[0;32m    646\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 647\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    648\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m lock:\n\u001b[0;32m    649\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\MyPC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\tree\\_classes.py:993\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.predict_proba\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    991\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    992\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X, check_input)\n\u001b[1;32m--> 993\u001b[0m proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    996\u001b[0m     proba \u001b[38;5;241m=\u001b[39m proba[:, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def process_data_stream(S, m, k, unique_labels):\n",
    "    \"\"\"\n",
    "    Processes data stream S using a weak Random Forest classifier.\n",
    "    - S: Data stream (list of data blocks Bi)\n",
    "    - m: Max size of classifier set C\n",
    "    - k: Min size of C to make predictions\n",
    "    \"\"\"\n",
    "    C = deque(maxlen=m) \n",
    "    pre = []\n",
    "    for Bi in S:\n",
    "        block_predictions = []\n",
    "        X = Bi.iloc[:, :-1] \n",
    "        y = Bi.iloc[:, -1]   \n",
    "        Ci = train_random_forest_classifier(X, y)\n",
    "        C.append(Ci)\n",
    "        while len(C) < k :\n",
    "            C.append(Ci)\n",
    "        for index, row in Bi.iterrows():\n",
    "            sample = pd.DataFrame([row[:-1]], columns=Bi.columns[:-1])\n",
    "            anpha = (1500 / len(Bi)) * 0.2\n",
    "            selected_classifiers = adaptive_ensemble_size(C, sample, unique_labels, anpha)\n",
    "            pre_sample = tendency_prediction(selected_classifiers, unique_labels)\n",
    "            block_predictions.append(pre_sample)\n",
    "        pre.append(block_predictions)\n",
    "    return C, pre\n",
    "m = 15\n",
    "k = 3\n",
    "unique_labels = set(df.iloc[:, -1])\n",
    "unique_labels = list(unique_labels)\n",
    "C, pre = process_data_stream(S, m, k, unique_labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
