{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sử dụng với dữ liệu creditcard https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud?resource=download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Train.csv')\n",
    "df.replace('?', pd.NA, inplace=True)\n",
    "\n",
    "# Fill missing values for categorical columns with the mode (most common value)\n",
    "for column in df.select_dtypes(include=['object']).columns:\n",
    "    df[column].fillna(df[column].mode()[0], inplace=True)\n",
    "\n",
    "# Fill missing values for numerical columns (if any) with the mean or median\n",
    "for column in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    df[column].fillna(df[column].mean(), inplace=True)\n",
    "\n",
    "# Convert categorical variables to numerical using one-hot encoding\n",
    "df = pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datastream(data, batch_size):\n",
    "    datastream = []\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        batch = data.iloc[i:i+batch_size]\n",
    "        datastream.append(batch)\n",
    "    return datastream\n",
    "batch_size = 150\n",
    "S = create_datastream(df, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest_classifier(X, y, n_estimators=20):\n",
    "    \"\"\"\n",
    "    Huấn luyện bộ phân loại Random forest trên dữ liệu X, y.\n",
    "    n_estimators: Số lượng cây trong Random forest.\n",
    "    \"\"\"\n",
    "    rf = RandomForestClassifier(n_estimators=n_estimators)\n",
    "    rf.fit(X, y)\n",
    "    return rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_ensemble_size(C, sample, unique_label, anpha, min_num = 3):\n",
    "    \"\"\"\n",
    "    Cơ chế adaptive_esemble \n",
    "    C : Bộ phân loại yếu\n",
    "    sample\n",
    "    unique_label : Tập hợp nhãn trong luồng dữ liệu\n",
    "    anpha : hyper parameter\n",
    "    min_num : số lượng C tối thiểu \n",
    "    \"\"\"\n",
    "    probability_list = []\n",
    "    for i in range(len(unique_label)):\n",
    "        li = [] \n",
    "        for j in range(len(C)):\n",
    "            probabilities = C[0].predict_proba(sample)[0]\n",
    "            probability_dict = {label: prob for label, prob in zip(C[0].classes_, probabilities)}\n",
    "            latest_proba = probability_dict.get(unique_label[i], 0)\n",
    "            probabilities1 = C[j].predict_proba(sample)[0]\n",
    "            probability_dict1 = {label: prob for label, prob in zip(C[j].classes_, probabilities1)}\n",
    "            current_proba = probability_dict1.get(unique_label[i], 0)\n",
    "            if len(li) < min_num:\n",
    "                li.append(current_proba)\n",
    "            else:\n",
    "                if abs(current_proba - latest_proba) < anpha :\n",
    "                    li.append(current_proba)\n",
    "                else: \n",
    "                    break   \n",
    "        probability_list.append(li)     \n",
    "    return probability_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(x, y):\n",
    "    \"\"\"Tính hồi quy tuyến tính\"\"\"\n",
    "    A = np.vstack([x, np.ones(len(x))]).T\n",
    "    m, c = np.linalg.lstsq(A, y, rcond=None)[0]\n",
    "    return m, c\n",
    "\n",
    "def tendency_prediction(probability_list, Y, epsilon=0.01):\n",
    "    \"\"\"\n",
    "    Thực hiện cơ chế dự đoán xu hướng\n",
    "    Input:\n",
    "    - probability_list: Danh sách xác suất cho mỗi mẫu\n",
    "    - Y: Danh sách các lớp trong luồng dữ liệu\n",
    "    - epsilon: Hệ số trọng số (mặc định là 0.01)\n",
    "    Output:\n",
    "    - Ps: Lớp dự đoán cho mẫu\n",
    "    \"\"\"\n",
    "    predicted_probabilities = []\n",
    "    for i in range(len(Y)):\n",
    "        li = probability_list[i]\n",
    "        x = np.arange(1, len(li) + 1)\n",
    "        y = np.array(li)\n",
    "        slope, intercept = linear_regression(x, y)\n",
    "        next_value = slope * (len(li) + 1) + intercept\n",
    "        li.append(next_value)\n",
    "        weighted_prob = sum([li[x - 1] * (1 + x * epsilon) for x in range(1, len(li) + 1)]) / len(li)\n",
    "        predicted_probabilities.append(weighted_prob)\n",
    "    Ps = Y[np.argmax(predicted_probabilities)]\n",
    "    \n",
    "    return Ps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_data_stream(S, m, k, unique_labels):\n",
    "    \"\"\"\n",
    "    Processes data stream S using a weak Random Forest classifier.\n",
    "    - S: Data stream (list of data blocks Bi)\n",
    "    - m: Max size of classifier set C\n",
    "    - k: Min size of C to make predictions\n",
    "    \"\"\"\n",
    "    C = deque(maxlen=m) \n",
    "    pre = []\n",
    "    for i in range(len(S) - 1):\n",
    "        Bi = S[i]\n",
    "        block_predictions = []\n",
    "        X = Bi.iloc[:, :-1] \n",
    "        y = Bi.iloc[:, -1]   \n",
    "        Ci = train_random_forest_classifier(X, y)\n",
    "        C.append(Ci)\n",
    "        if len(C) < k:\n",
    "            continue\n",
    "        Bi_1 = S[i + 1]\n",
    "        for index, row in Bi_1.iterrows():\n",
    "            sample = pd.DataFrame([row[:-1]], columns=Bi.columns[:-1])\n",
    "            anpha = (30 / len(Bi_1)) * 0.2\n",
    "            selected_classifiers = adaptive_ensemble_size(C, sample, unique_labels, anpha)\n",
    "            pre_sample = tendency_prediction(selected_classifiers, unique_labels)\n",
    "            block_predictions.append(pre_sample)\n",
    "        pre.append(block_predictions)\n",
    "    return C, pre\n",
    "m = 15\n",
    "k = 3\n",
    "unique_labels = set(df.iloc[:, -1])\n",
    "unique_labels = list(unique_labels)\n",
    "C, pre = process_data_stream(S, m, k, unique_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.0\n",
      "Accuracy: nan%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MyPC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\MyPC\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\lib\\function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "C:\\Users\\MyPC\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# Giả sử rằng pre là danh sách chứa các dự đoán và bạn muốn so sánh với các nhãn thực tế từ Bi_1\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for i in range(2, len(pre)):\n",
    "    # Thêm nhãn thực tế từ Bi_1\n",
    "    Bi_1 = S[i + 1]  # Chúng ta đã sử dụng Bi_1 trong process_data_stream\n",
    "    y_true.extend(Bi_1.iloc[:, -1].tolist())  # Nhãn thực tế\n",
    "    \n",
    "    # Thêm dự đoán vào danh sách y_pred\n",
    "    y_pred.extend(pre[i])  # Dự đoán từ từng block\n",
    "\n",
    "# Chuyển đổi về dạng numpy array nếu cần\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
