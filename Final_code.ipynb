{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from collections import deque\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('creditcard.csv')\n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datastream_by_time(data, time_interval):\n",
    "    datastream = []\n",
    "    start_time = int(data['Time'].min())\n",
    "    end_time = int(data['Time'].max())\n",
    "    \n",
    "    for t in range(start_time, end_time + 1, time_interval):\n",
    "        block = data[(data['Time'] >= t) & (data['Time'] < t + time_interval)]\n",
    "        if not block.empty:\n",
    "            datastream.append(block)\n",
    "    \n",
    "    return datastream\n",
    "time_interval = 3000\n",
    "S = create_datastream_by_time(df, time_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataStreamProcessor:\n",
    "    def __init__(self, m, k, unique_labels):\n",
    "        self.m = m\n",
    "        self.k = k\n",
    "        self.unique_labels = unique_labels\n",
    "        self.C = deque(maxlen=m)\n",
    "        self.pre = []\n",
    "        self.true_labels = []\n",
    "        self.class_1_samples = pd.DataFrame()\n",
    "\n",
    "    def process_data_stream(self, S):\n",
    "        for i in range(len(S) - 1):\n",
    "            Bi = S[i]\n",
    "            self._update_class_1_samples(Bi)\n",
    "            X = Bi.iloc[:, :-1]\n",
    "            y = Bi.iloc[:, -1]\n",
    "            Ci = self._train_random_forest_classifier(X, y)\n",
    "            self.C.append(Ci)\n",
    "            if len(self.C) < self.k:\n",
    "                next_block = S[i + 1]\n",
    "                S[i + 1] = pd.concat([next_block, self.class_1_samples], ignore_index=True)\n",
    "                continue\n",
    "            Bi_1 = S[i + 1]\n",
    "            block_predictions = self._predict_block(Bi_1)\n",
    "            self.pre.append(block_predictions)\n",
    "            self.true_labels.append(list(Bi_1.iloc[:, -1]))\n",
    "            if i + 1 < len(S):\n",
    "                self._update_next_block(S, i)\n",
    "        return self.C, self.pre, self.true_labels\n",
    "\n",
    "    def _update_class_1_samples(self, Bi):\n",
    "        class_1_new_samples = Bi[Bi['Class'] == 1]\n",
    "        self.class_1_samples = pd.concat([self.class_1_samples, class_1_new_samples], ignore_index=True)\n",
    "        if len(self.class_1_samples) > 40:\n",
    "            self.class_1_samples = self.class_1_samples.iloc[-40:]\n",
    "\n",
    "    def _update_next_block(self, S, i):\n",
    "        next_block = S[i + 1]\n",
    "        updated_block = pd.concat([next_block, self.class_1_samples], ignore_index=True)\n",
    "    \n",
    "        X = updated_block.drop(columns=['Class'])\n",
    "        y = updated_block['Class']\n",
    "\n",
    "        smote = SMOTE(sampling_strategy=0.15)\n",
    "        X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "        S[i + 1] = pd.concat([X_resampled, y_resampled], axis=1)\n",
    "\n",
    "    def _predict_block(self, Bi):\n",
    "        block_predictions = []\n",
    "        for _, row in Bi.iterrows():\n",
    "            sample = pd.DataFrame([row[:-1]], columns=Bi.columns[:-1])\n",
    "            anpha = (3000 / len(Bi)) * 0.2\n",
    "            selected_classifiers = self._adaptive_ensemble_size(sample, anpha)\n",
    "            pre_sample = self._tendency_prediction(selected_classifiers)\n",
    "            block_predictions.append(pre_sample)\n",
    "        return block_predictions\n",
    "\n",
    "    def _train_random_forest_classifier(self, X, y, n_estimators=70, max_depth=None, min_samples_split=2, min_samples_leaf=1, class_weight=\"balanced\", random_state=42):\n",
    "        rf = RandomForestClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            class_weight=class_weight,\n",
    "            random_state=random_state\n",
    "        )\n",
    "        rf.fit(X, y)\n",
    "        return rf\n",
    "\n",
    "    def _adaptive_ensemble_size(self, sample, anpha, min_num=3):\n",
    "        probability_list = []\n",
    "        sample_proba = [clf.predict_proba(sample)[0] for clf in self.C]\n",
    "        for label in self.unique_labels:\n",
    "            li = []\n",
    "            latest_proba = None\n",
    "            for proba in sample_proba:\n",
    "                probability_dict = {lbl: prob for lbl, prob in zip(self.C[0].classes_, proba)}\n",
    "                current_proba = probability_dict.get(label, 0)\n",
    "                if len(li) < min_num:\n",
    "                    li.append(current_proba)\n",
    "                else:\n",
    "                    if latest_proba is None:\n",
    "                        latest_proba = probability_dict.get(label, 0)\n",
    "                    if abs(current_proba - latest_proba) < anpha:\n",
    "                        li.append(current_proba)\n",
    "                    else:\n",
    "                        break\n",
    "            probability_list.append(li)\n",
    "        return probability_list\n",
    "\n",
    "    def _tendency_prediction(self, probability_list, epsilon=0.01):\n",
    "        predicted_probabilities = []\n",
    "        for li in probability_list:\n",
    "            x = np.arange(1, len(li) + 1)\n",
    "            y = np.array(li)\n",
    "            slope, intercept = self._linear_regression(x, y)\n",
    "            next_value = slope * (len(li) + 2) + intercept\n",
    "            li = [next_value] + li\n",
    "            weights = 1 - np.arange(1, len(li) + 1) * epsilon\n",
    "            weighted_prob = np.dot(li, weights) / len(li)\n",
    "            predicted_probabilities.append(weighted_prob)\n",
    "        if predicted_probabilities[0] < predicted_probabilities[1] + 0.5:\n",
    "            return self.unique_labels[1]\n",
    "        Ps = self.unique_labels[np.argmax(predicted_probabilities)]        \n",
    "        return Ps\n",
    "\n",
    "    def _linear_regression(self, x, y):\n",
    "        A = np.vstack([x, np.ones(len(x))]).T\n",
    "        m, c = np.linalg.lstsq(A, y, rcond=None)[0]\n",
    "        return m, c\n",
    "\n",
    "    def compute_metrics(self):\n",
    "        all_predictions = [pred for block in self.pre for pred in block]\n",
    "        all_true_labels = [label for block in self.true_labels for label in block]\n",
    "        if len(all_predictions) > 0 and len(all_true_labels) > 0:\n",
    "            precision = precision_score(all_true_labels, all_predictions, average='binary', pos_label=1)\n",
    "            recall = recall_score(all_true_labels, all_predictions, average='binary', pos_label=1)\n",
    "            f1 = f1_score(all_true_labels, all_predictions, average='binary', pos_label=1)\n",
    "            accuracy = accuracy_score(all_true_labels, all_predictions)\n",
    "            return precision, recall, f1, accuracy\n",
    "        else:\n",
    "            return None, None, None, None\n",
    "# Example usage\n",
    "m = 15\n",
    "k = 3\n",
    "unique_labels = list(set(df.iloc[:, -1]))\n",
    "processor = DataStreamProcessor(m, k, unique_labels)\n",
    "C, pre, true_labels = processor.process_data_stream(S)\n",
    "precision, recall, f1, accuracy = processor.compute_metrics()\n",
    "\n",
    "if precision is not None:\n",
    "    print(\"Total Metrics:\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall: {recall:.4f}\")\n",
    "    print(f\"  F1 Score: {f1:.4f}\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "else:\n",
    "    print(\"No predictions or true labels available to compute metrics.\")\n",
    "\n",
    "processor.plot_block_f1_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
