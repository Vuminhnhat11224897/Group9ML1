{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(40)\n",
    "\n",
    "# Define the range for x1, x2, x3\n",
    "x_range = (0, 10)\n",
    "\n",
    "# Define the sequence of θ values\n",
    "theta_values = [6, 13, 14, 15, 10, 9, 8, 7, 10, 9, 5]\n",
    "\n",
    "# Total number of samples\n",
    "total_samples = 75000\n",
    "\n",
    "# Number of samples per θ value\n",
    "samples_per_theta = total_samples // len(theta_values)\n",
    "\n",
    "# Initialize an empty list to store the dataset\n",
    "data = []\n",
    "\n",
    "# Generate the dataset\n",
    "for theta in theta_values:\n",
    "    for _ in range(samples_per_theta):\n",
    "        x1 = np.random.uniform(*x_range)\n",
    "        x2 = np.random.uniform(*x_range)\n",
    "        x3 = np.random.uniform(*x_range)\n",
    "        label = '1' if x1 + x2 > theta else '0'\n",
    "        data.append([x1, x2, x3, label])\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data, columns=['x1', 'x2', 'x3', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datastream(data, batch_size):\n",
    "    datastream = []\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        batch = data.iloc[i:i+batch_size]\n",
    "        datastream.append(batch)\n",
    "    return datastream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest_classifier(X, y, n_estimators=50):\n",
    "    \"\"\"\n",
    "    Huấn luyện bộ phân loại Random forest trên dữ liệu X, y.\n",
    "    n_estimators: Số lượng cây trong Random forest.\n",
    "    \"\"\"\n",
    "    rf = RandomForestClassifier(n_estimators=n_estimators)\n",
    "    rf.fit(X, y)\n",
    "    return rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_ensemble_size(C, sample, unique_label, anpha, min_num = 3):\n",
    "    \"\"\"\n",
    "    Cơ chế adaptive_esemble \n",
    "    C : Bộ phân loại yếu\n",
    "    sample\n",
    "    unique_label : Tập hợp nhãn trong luồng dữ liệu\n",
    "    anpha : hyper parameter\n",
    "    min_num : số lượng C tối thiểu \n",
    "    \"\"\"\n",
    "    probability_list = []\n",
    "    for i in range(len(unique_label)):\n",
    "        li = [] \n",
    "        for j in range(len(C)):\n",
    "            probabilities = C[0].predict_proba(sample)[0]\n",
    "            probability_dict = {label: prob for label, prob in zip(C[0].classes_, probabilities)}\n",
    "            latest_proba = probability_dict.get(unique_label[i], 0)\n",
    "            probabilities1 = C[j].predict_proba(sample)[0]\n",
    "            probability_dict1 = {label: prob for label, prob in zip(C[j].classes_, probabilities1)}\n",
    "            current_proba = probability_dict1.get(unique_label[i], 0)\n",
    "            if len(li) < min_num:\n",
    "                li.append(current_proba)\n",
    "            else:\n",
    "                if abs(current_proba - latest_proba) < anpha :\n",
    "                    li.append(current_proba)\n",
    "                else: \n",
    "                    break   \n",
    "        probability_list.append(li)     \n",
    "    return probability_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(x, y):\n",
    "    \"\"\"Tính hồi quy tuyến tính\"\"\"\n",
    "    A = np.vstack([x, np.ones(len(x))]).T\n",
    "    m, c = np.linalg.lstsq(A, y, rcond=None)[0]\n",
    "    return m, c\n",
    "\n",
    "def tendency_prediction(probability_list, Y, epsilon=0.01):\n",
    "    \"\"\"\n",
    "    Thực hiện cơ chế dự đoán xu hướng\n",
    "    Input:\n",
    "    - probability_list: Danh sách xác suất cho mỗi mẫu\n",
    "    - Y: Danh sách các lớp trong luồng dữ liệu\n",
    "    - epsilon: Hệ số trọng số (mặc định là 0.01)\n",
    "    Output:\n",
    "    - Ps: Lớp dự đoán cho mẫu\n",
    "    \"\"\"\n",
    "    predicted_probabilities = []\n",
    "    for i in range(len(Y)):\n",
    "        li = probability_list[i]\n",
    "        x = np.arange(1, len(li) + 1)\n",
    "        y = np.array(li)\n",
    "        slope, intercept = linear_regression(x, y)\n",
    "        next_value = slope * (len(li) + 2) + intercept\n",
    "        li.insert(0, next_value)\n",
    "        weighted_prob = sum([li[x - 1] * (1 - x * epsilon) for x in range(1, len(li) + 1)]) / len(li)\n",
    "        predicted_probabilities.append(weighted_prob)\n",
    "    Ps = Y[np.argmax(predicted_probabilities)]\n",
    "    \n",
    "    return Ps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_stream(S, m, k, unique_labels):\n",
    "    C = deque(maxlen=m)\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    pre = []\n",
    "    block_accuracies = []  # Danh sách để lưu trữ độ chính xác của từng block\n",
    "\n",
    "    for i in range(len(S) - 1):\n",
    "        Bi = S[i]\n",
    "        block_predictions = []\n",
    "        X = Bi.iloc[:, :-1]\n",
    "        y = Bi.iloc[:, -1]\n",
    "        Ci = train_random_forest_classifier(X, y)\n",
    "        C.append(Ci)\n",
    "        if len(C) < k:\n",
    "            continue\n",
    "        Bi_1 = S[i + 1]\n",
    "        for index, row in Bi_1.iterrows():\n",
    "            sample = pd.DataFrame([row[:-1]], columns=Bi.columns[:-1])\n",
    "            anpha = (1500 / len(Bi_1)) * 0.2\n",
    "            selected_classifiers = adaptive_ensemble_size(C, sample, unique_labels, anpha)\n",
    "            pre_sample = tendency_prediction(selected_classifiers, unique_labels)\n",
    "            block_predictions.append(pre_sample)\n",
    "            true_labels.append(row.iloc[-1])\n",
    "            predicted_labels.append(pre_sample)\n",
    "        pre.append(block_predictions)\n",
    "\n",
    "        # Tính toán độ chính xác cho block hiện tại\n",
    "        block_accuracy = accuracy_score(true_labels[-len(Bi_1):], predicted_labels[-len(Bi_1):])\n",
    "        block_accuracies.append(block_accuracy)\n",
    "    \n",
    "    precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "    recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    \n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1-Score: {f1}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "    # Trực quan hóa độ chính xác của từng block\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(block_accuracies, marker='o', linestyle='-', color='b')\n",
    "    plt.title('Accuracy of Each Block')\n",
    "    plt.xlabel('Block Index')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Main execution\n",
    "batch_size = 500\n",
    "S = create_datastream(df, batch_size)\n",
    "m = 15\n",
    "k = 3\n",
    "unique_labels = list(set(df.iloc[:, -1]))\n",
    "process_data_stream(S, m, k, unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train_random_forest_classifier(X, y):\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X, y)\n",
    "    return clf\n",
    "\n",
    "def process_data_stream(S):\n",
    "    \"\"\"\n",
    "    Processes data stream S using a Random Forest classifier.\n",
    "    - S: Data stream (list of data blocks Bi)\n",
    "    \"\"\"\n",
    "    # Use the first block as the training set\n",
    "    Bi = S[0]\n",
    "    X_train = Bi.iloc[:, :-1]\n",
    "    y_train = Bi.iloc[:, -1]\n",
    "    model = train_random_forest_classifier(X_train, y_train)\n",
    "\n",
    "    accuracies = []\n",
    "\n",
    "    # Predict and calculate accuracy for each subsequent block\n",
    "    for i in range(1, len(S)):\n",
    "        Bi_1 = S[i]\n",
    "        X_test = Bi_1.iloc[:, :-1]\n",
    "        y_test = Bi_1.iloc[:, -1]\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "    average_accuracy = sum(accuracies) / len(accuracies)\n",
    "    print(average_accuracy)\n",
    "    # Plot the accuracies\n",
    "    plt.plot(range(1, len(S)), accuracies, marker='o')\n",
    "    plt.xlabel('Block Index')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy for Each Block')\n",
    "    plt.show()\n",
    "\n",
    "process_data_stream(S) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
