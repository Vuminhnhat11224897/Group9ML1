{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sử dụng với dữ liệu creditcard https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud?resource=download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score  \n",
    "from sklearn.metrics import accuracy_score  \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard.csv')\n",
    "def create_datastream_by_time(data, time_interval):\n",
    "    datastream = []\n",
    "    start_time = int(data['Time'].min())\n",
    "    end_time = int(data['Time'].max())\n",
    "    \n",
    "    for t in range(start_time, end_time + 1, time_interval):\n",
    "        block = data[(data['Time'] >= t) & (data['Time'] < t + time_interval)]\n",
    "        if not block.empty:\n",
    "            datastream.append(block)\n",
    "    \n",
    "    return datastream\n",
    "time_interval = 7200\n",
    "S = create_datastream_by_time(df, time_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest_classifier(X, y):\n",
    "    \"\"\"\n",
    "    Huấn luyện bộ phân loại Random Forest trên dữ liệu X, y.\n",
    "    \"\"\"\n",
    "    class_count = np.bincount(y)\n",
    "\n",
    "    # Kiểm tra số lượng lớp có trong y\n",
    "    if len(class_count) < 2 :\n",
    "        rf = RandomForestClassifier(n_estimators=10, class_weight={0:1})\n",
    "        rf.fit(X, y)\n",
    "        return rf \n",
    "    else:\n",
    "        class_ratio = class_count[1] / class_count[0]\n",
    "        lambda_min = 1 \n",
    "        lambda_value = lambda_min + (1 + class_ratio) * lambda_min\n",
    "\n",
    "        # Huấn luyện bộ phân loại Random Forest\n",
    "        rf = RandomForestClassifier(n_estimators=10, class_weight={0: 1, 1: lambda_value})\n",
    "        rf.fit(X, y)\n",
    "        return rf  # Trả về mô hình đã huấn luyện\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_ensemble_size(C, sample, unique_label, anpha, min_num = 3):\n",
    "    \"\"\"\n",
    "    Cơ chế adaptive_esemble \n",
    "    C : Bộ phân loại yếu\n",
    "    sample\n",
    "    unique_label : Tập hợp nhãn trong luồng dữ liệu\n",
    "    anpha : hyper parameter\n",
    "    min_num : số lượng C tối thiểu \n",
    "    \"\"\"\n",
    "    probability_list = []\n",
    "    for i in range(len(unique_label)):\n",
    "        li = [] \n",
    "        for j in range(len(C)):\n",
    "            probabilities = C[0].predict_proba(sample)[0]\n",
    "            probability_dict = {label: prob for label, prob in zip(C[0].classes_, probabilities)}\n",
    "            latest_proba = probability_dict.get(unique_label[i], 0)\n",
    "            probabilities1 = C[j].predict_proba(sample)[0]\n",
    "            probability_dict1 = {label: prob for label, prob in zip(C[j].classes_, probabilities1)}\n",
    "            current_proba = probability_dict1.get(unique_label[i], 0)\n",
    "            if len(li) < min_num:\n",
    "                li.append(current_proba)\n",
    "            else:\n",
    "                if abs(current_proba - latest_proba) < anpha :\n",
    "                    li.append(current_proba)\n",
    "                else: \n",
    "                    break   \n",
    "        probability_list.append(li)     \n",
    "    return probability_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(x, y):\n",
    "    \"\"\"Tính hồi quy tuyến tính\"\"\"\n",
    "    A = np.vstack([x, np.ones(len(x))]).T\n",
    "    m, c = np.linalg.lstsq(A, y, rcond=None)[0]\n",
    "    return m, c\n",
    "\n",
    "def tendency_prediction(probability_list, Y, epsilon=0.01):\n",
    "    \"\"\"\n",
    "    Thực hiện cơ chế dự đoán xu hướng\n",
    "    Input:\n",
    "    - probability_list: Danh sách xác suất cho mỗi mẫu\n",
    "    - Y: Danh sách các lớp trong luồng dữ liệu\n",
    "    - epsilon: Hệ số trọng số (mặc định là 0.01)\n",
    "    Output:\n",
    "    - Ps: Lớp dự đoán cho mẫu\n",
    "    \"\"\"\n",
    "    predicted_probabilities = []\n",
    "    for i in range(len(Y)):\n",
    "        li = probability_list[i]\n",
    "        x = np.arange(1, len(li) + 1)\n",
    "        y = np.array(li)\n",
    "        slope, intercept = linear_regression(x, y)\n",
    "        next_value = slope * (len(li) + 1) + intercept\n",
    "        li.append(next_value)\n",
    "        weighted_prob = sum([li[x] * (1 + x * epsilon) for x in range(len(li))]) / len(li)\n",
    "        predicted_probabilities.append(weighted_prob)\n",
    "    Ps = Y[np.argmax(predicted_probabilities)]\n",
    "    \n",
    "    return Ps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MyPC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "m = 15\n",
    "k = 3\n",
    "unique_labels = set(df.iloc[:, -1])\n",
    "unique_labels = list(unique_labels)\n",
    "\n",
    "b1 = pd.DataFrame(S[0])\n",
    "minority_samples = b1[b1['Class'] == 1].drop('Class', axis=1)\n",
    "    # Tạo K-means\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "kmeans.fit(minority_samples)\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "    # Tạo thêm các mẫu gần cụm\n",
    "new_samples = []\n",
    "for centroid in centroids:\n",
    "        for _ in range(4 // 2):\n",
    "            noise = np.random.normal(0, 0.1, centroid.shape)\n",
    "            new_sample = centroid + noise\n",
    "            new_samples.append(new_sample)\n",
    "\n",
    "new_samples_df = pd.DataFrame(new_samples, columns=minority_samples.columns)\n",
    "new_samples_df['Class'] = 1\n",
    "\n",
    "b1_augmented = pd.concat([b1, new_samples_df], ignore_index=True)\n",
    "\n",
    "    # Smote\n",
    "X = b1_augmented.drop('Class', axis=1)\n",
    "y = b1_augmented['Class']\n",
    "        \n",
    "smote = SMOTE(sampling_strategy={1:m}, random_state=42)\n",
    "X_smote, y_smote = smote.fit_resample(X, y)\n",
    "b1_augmented = pd.DataFrame(X_smote, columns=X.columns)\n",
    "b1_augmented['Class'] = y_smote\n",
    "\n",
    "unique_labels = list(set(y_smote))\n",
    "\n",
    "    # Tạo danh sách tất cả các block, bao gồm b1\n",
    "S = [b1_augmented] + S[1:6]\n",
    "\n",
    "def process_data_stream(S, m, k, unique_labels):\n",
    "    \"\"\"\n",
    "    Processes data stream S using a weak Random Forest classifier.\n",
    "    - S: Data stream (list of data blocks Bi)\n",
    "    - m: Max size of classifier set C\n",
    "    - k: Min size of C to make predictions\n",
    "    \"\"\"\n",
    "    C = deque(maxlen=m) \n",
    "    pre = []\n",
    "    class_1_samples = pd.DataFrame()\n",
    "    true_labels = []\n",
    "    for i in range(20):\n",
    "        Bi = S[i]\n",
    "        class_1_new_samples = Bi[Bi['Class'] == 1]\n",
    "        class_1_samples = pd.concat([class_1_samples, class_1_new_samples], ignore_index=True)\n",
    "\n",
    "        if len(class_1_samples) > 20:\n",
    "            class_1_samples = class_1_samples.iloc[-20:]  # Giữ lại m mẫu mới nhất\n",
    "        if i + 1 < len(S):\n",
    "            next_block = S[i + 1]\n",
    "            class_1_samples_df = class_1_samples\n",
    "            S[i + 1] = pd.concat([next_block, class_1_samples_df], ignore_index=True)\n",
    "        block_predictions = []\n",
    "        X = Bi.iloc[:, :-1] \n",
    "        y = Bi.iloc[:, -1]   \n",
    "        Ci = train_random_forest_classifier(X, y)\n",
    "        C.append(Ci)\n",
    "        while len(C) < k :\n",
    "            C.append(Ci)\n",
    "        for index, row in Bi.iterrows():\n",
    "            sample = pd.DataFrame([row[:-1]], columns=Bi.columns[:-1])\n",
    "            anpha = (1500 / len(Bi)) * 0.2\n",
    "            selected_classifiers = adaptive_ensemble_size(C, sample, unique_labels, anpha)\n",
    "            pre_sample = tendency_prediction(selected_classifiers, unique_labels)\n",
    "            block_predictions.append(pre_sample)\n",
    "        pre.append(block_predictions)\n",
    "        true_labels.append(list(y))\n",
    "    return C, pre, true_labels\n",
    "C, pre, true_labels = process_data_stream(S, m, k, unique_labels)\n",
    "all_predictions = [pred for block in pre for pred in block]  # Tất cả dự đoán\n",
    "all_true_labels = [label for block in true_labels for label in block]  # Tất cả nhãn đúng\n",
    "\n",
    "# Tính toán chỉ số tổng\n",
    "if len(all_predictions) > 0 and len(all_true_labels) > 0:\n",
    "    precision = precision_score(all_true_labels, all_predictions, average='binary', pos_label=1)\n",
    "    recall = recall_score(all_true_labels, all_predictions, average='binary', pos_label=1)\n",
    "    f1 = f1_score(all_true_labels, all_predictions, average='binary', pos_label=1)\n",
    "    \n",
    "    print(\"Total Metrics:\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall: {recall:.4f}\")\n",
    "    print(f\"  F1 Score: {f1:.4f}\")\n",
    "else:\n",
    "    print(\"No predictions or true labels available to compute metrics.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
