{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sử dụng với dữ liệu creditcard https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud?resource=download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score  \n",
    "from sklearn.metrics import accuracy_score  \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard.csv')\n",
    "\n",
    "def create_datastream_by_time(data, time_interval):\n",
    "    datastream = []\n",
    "    start_time = int(data['Time'].min())\n",
    "    end_time = int(data['Time'].max())\n",
    "    \n",
    "    for t in range(start_time, end_time + 1, time_interval):\n",
    "        block = data[(data['Time'] >= t) & (data['Time'] < t + time_interval)]\n",
    "        if not block.empty:\n",
    "            datastream.append(block)\n",
    "    \n",
    "    return datastream\n",
    "time_interval = 5000\n",
    "S = create_datastream_by_time(df, time_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest_classifier(X, y):\n",
    "    \"\"\"\n",
    "    Huấn luyện bộ phân loại Random Forest trên dữ liệu X, y.\n",
    "    \"\"\"\n",
    "    class_count = np.bincount(y)\n",
    "\n",
    "    # Kiểm tra số lượng lớp có trong y\n",
    "    if len(class_count) < 2 :\n",
    "        rf = RandomForestClassifier(n_estimators=10, class_weight={0:1})\n",
    "        rf.fit(X, y)\n",
    "        return rf \n",
    "    else:\n",
    "        class_ratio = class_count[1] / class_count[0]\n",
    "        lambda_min = 1 \n",
    "        lambda_value = lambda_min + (1 + class_ratio) * lambda_min\n",
    "\n",
    "        # Huấn luyện bộ phân loại Random Forest\n",
    "        rf = RandomForestClassifier(n_estimators=10, class_weight={0: 1, 1: lambda_value})\n",
    "        rf.fit(X, y)\n",
    "        return rf  # Trả về mô hình đã huấn luyện\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_ensemble_size(C, sample, unique_label, anpha, min_num = 3):\n",
    "    \"\"\"\n",
    "    Cơ chế adaptive_esemble \n",
    "    C : Bộ phân loại yếu\n",
    "    sample\n",
    "    unique_label : Tập hợp nhãn trong luồng dữ liệu\n",
    "    anpha : hyper parameter\n",
    "    min_num : số lượng C tối thiểu \n",
    "    \"\"\"\n",
    "    probability_list = []\n",
    "    for i in range(len(unique_label)):\n",
    "        li = [] \n",
    "        for j in range(len(C)):\n",
    "            probabilities = C[0].predict_proba(sample)[0]\n",
    "            probability_dict = {label: prob for label, prob in zip(C[0].classes_, probabilities)}\n",
    "            latest_proba = probability_dict.get(unique_label[i], 0)\n",
    "            probabilities1 = C[j].predict_proba(sample)[0]\n",
    "            probability_dict1 = {label: prob for label, prob in zip(C[j].classes_, probabilities1)}\n",
    "            current_proba = probability_dict1.get(unique_label[i], 0)\n",
    "            if len(li) < min_num:\n",
    "                li.append(current_proba)\n",
    "            else:\n",
    "                if abs(current_proba - latest_proba) < anpha :\n",
    "                    li.append(current_proba)\n",
    "                else: \n",
    "                    break   \n",
    "        probability_list.append(li)     \n",
    "    return probability_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(x, y):\n",
    "    \"\"\"Tính hồi quy tuyến tính\"\"\"\n",
    "    A = np.vstack([x, np.ones(len(x))]).T\n",
    "    m, c = np.linalg.lstsq(A, y, rcond=None)[0]\n",
    "    return m, c\n",
    "\n",
    "def tendency_prediction(probability_list, Y, epsilon=0.01):\n",
    "    \"\"\"\n",
    "    Thực hiện cơ chế dự đoán xu hướng\n",
    "    Input:\n",
    "    - probability_list: Danh sách xác suất cho mỗi mẫu\n",
    "    - Y: Danh sách các lớp trong luồng dữ liệu\n",
    "    - epsilon: Hệ số trọng số (mặc định là 0.01)\n",
    "    Output:\n",
    "    - Ps: Lớp dự đoán cho mẫu\n",
    "    \"\"\"\n",
    "    predicted_probabilities = []\n",
    "    for i in range(len(Y)):\n",
    "        li = probability_list[i]\n",
    "        x = np.arange(1, len(li) + 1)\n",
    "        y = np.array(li)\n",
    "        slope, intercept = linear_regression(x, y)\n",
    "        next_value = slope * (len(li) + 1) + intercept\n",
    "        li.append(next_value)\n",
    "        weighted_prob = sum([li[x] * (1 + (x + 1) * epsilon) for x in range(len(li))]) / len(li)\n",
    "        predicted_probabilities.append(weighted_prob)\n",
    "    Ps = Y[np.argmax(predicted_probabilities)]\n",
    "    \n",
    "    return Ps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MyPC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 86\u001b[0m\n\u001b[0;32m     84\u001b[0m         true_labels\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlist\u001b[39m(y))\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m C, pre, true_labels\n\u001b[1;32m---> 86\u001b[0m C, pre, true_labels \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_data_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munique_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m all_predictions \u001b[38;5;241m=\u001b[39m [pred \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m pre \u001b[38;5;28;01mfor\u001b[39;00m pred \u001b[38;5;129;01min\u001b[39;00m block]  \u001b[38;5;66;03m# Tất cả dự đoán\u001b[39;00m\n\u001b[0;32m     88\u001b[0m all_true_labels \u001b[38;5;241m=\u001b[39m [label \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m true_labels \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m block]  \u001b[38;5;66;03m# Tất cả nhãn đúng\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[71], line 80\u001b[0m, in \u001b[0;36mprocess_data_stream\u001b[1;34m(S, m, k, unique_labels)\u001b[0m\n\u001b[0;32m     78\u001b[0m sample \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([row[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]], columns\u001b[38;5;241m=\u001b[39mBi\u001b[38;5;241m.\u001b[39mcolumns[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     79\u001b[0m anpha \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1500\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(Bi)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.2\u001b[39m\n\u001b[1;32m---> 80\u001b[0m selected_classifiers \u001b[38;5;241m=\u001b[39m \u001b[43madaptive_ensemble_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munique_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m pre_sample \u001b[38;5;241m=\u001b[39m tendency_prediction(selected_classifiers, unique_labels)\n\u001b[0;32m     82\u001b[0m block_predictions\u001b[38;5;241m.\u001b[39mappend(pre_sample)\n",
      "Cell \u001b[1;32mIn[69], line 14\u001b[0m, in \u001b[0;36madaptive_ensemble_size\u001b[1;34m(C, sample, unique_label, anpha, min_num)\u001b[0m\n\u001b[0;32m     12\u001b[0m li \u001b[38;5;241m=\u001b[39m [] \n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(C)):\n\u001b[1;32m---> 14\u001b[0m     probabilities \u001b[38;5;241m=\u001b[39m \u001b[43mC\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     15\u001b[0m     probability_dict \u001b[38;5;241m=\u001b[39m {label: prob \u001b[38;5;28;01mfor\u001b[39;00m label, prob \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(C[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mclasses_, probabilities)}\n\u001b[0;32m     16\u001b[0m     latest_proba \u001b[38;5;241m=\u001b[39m probability_dict\u001b[38;5;241m.\u001b[39mget(unique_label[i], \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\MyPC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:876\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    871\u001b[0m all_proba \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    872\u001b[0m     np\u001b[38;5;241m.\u001b[39mzeros((X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], j), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39matleast_1d(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_)\n\u001b[0;32m    874\u001b[0m ]\n\u001b[0;32m    875\u001b[0m lock \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mLock()\n\u001b[1;32m--> 876\u001b[0m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequire\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msharedmem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_accumulate_prediction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_proba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimators_\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m proba \u001b[38;5;129;01min\u001b[39;00m all_proba:\n\u001b[0;32m    882\u001b[0m     proba \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_)\n",
      "File \u001b[1;32mc:\\Users\\MyPC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MyPC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\MyPC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\MyPC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\MyPC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:647\u001b[0m, in \u001b[0;36m_accumulate_prediction\u001b[1;34m(predict, X, out, lock)\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_accumulate_prediction\u001b[39m(predict, X, out, lock):\n\u001b[0;32m    641\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;124;03m    This is a utility function for joblib's Parallel.\u001b[39;00m\n\u001b[0;32m    643\u001b[0m \n\u001b[0;32m    644\u001b[0m \u001b[38;5;124;03m    It can't go locally in ForestClassifier or ForestRegressor, because joblib\u001b[39;00m\n\u001b[0;32m    645\u001b[0m \u001b[38;5;124;03m    complains that it cannot pickle it when placed there.\u001b[39;00m\n\u001b[0;32m    646\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 647\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    648\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m lock:\n\u001b[0;32m    649\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\MyPC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\tree\\_classes.py:993\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.predict_proba\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    991\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    992\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X, check_input)\n\u001b[1;32m--> 993\u001b[0m proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    996\u001b[0m     proba \u001b[38;5;241m=\u001b[39m proba[:, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "m = 15\n",
    "k = 3\n",
    "unique_labels = set(df.iloc[:, -1])\n",
    "unique_labels = list(unique_labels)\n",
    "\n",
    "b1 = pd.concat(S[:m], ignore_index=True)\n",
    "minority_samples = b1[b1['Class'] == 1].drop('Class', axis=1)\n",
    "    # Tạo K-means\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "kmeans.fit(minority_samples)\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "    # Tạo thêm các mẫu gần cụm\n",
    "new_samples = []\n",
    "for centroid in centroids:\n",
    "        for _ in range(4 // 2):\n",
    "            noise = np.random.normal(0, 0.1, centroid.shape)\n",
    "            new_sample = centroid + noise\n",
    "            new_samples.append(new_sample)\n",
    "\n",
    "new_samples_df = pd.DataFrame(new_samples, columns=minority_samples.columns)\n",
    "new_samples_df['Class'] = 1\n",
    "\n",
    "b1_augmented = pd.concat([b1, new_samples_df], ignore_index=True)\n",
    "\n",
    "class_1_rows = b1_augmented[b1_augmented['Class'] == 1]\n",
    "num_class_1_rows = class_1_rows.shape[0]\n",
    "\n",
    "    # Smote\n",
    "X = b1_augmented.drop('Class', axis=1)\n",
    "y = b1_augmented['Class']\n",
    "\n",
    "\n",
    "\n",
    "smote = SMOTE(sampling_strategy={1:num_class_1_rows}, random_state=42)\n",
    "X_smote, y_smote = smote.fit_resample(X, y)\n",
    "\n",
    "b1_augmented = pd.DataFrame(X_smote, columns=X.columns)\n",
    "b1_augmented['Class'] = y_smote\n",
    "\n",
    "unique_labels = list(set(y_smote))\n",
    "\n",
    "    # Tạo danh sách tất cả các block, bao gồm b1\n",
    "S = [b1_augmented] + S[m:]\n",
    "\n",
    "def process_data_stream(S, m, k, unique_labels):\n",
    "    \"\"\"\n",
    "    Processes data stream S using a weak Random Forest classifier.\n",
    "    - S: Data stream (list of data blocks Bi)\n",
    "    - m: Max size of classifier set C\n",
    "    - k: Min size of C to make predictions\n",
    "    \"\"\"\n",
    "    C = deque(maxlen=m) \n",
    "    pre = []\n",
    "    class_1_samples = pd.DataFrame()\n",
    "    true_labels = []\n",
    "    for i in range(10):\n",
    "        Bi = S[i]\n",
    "        class_1_new_samples = Bi[Bi['Class'] == 1]\n",
    "        class_1_samples = pd.concat([class_1_samples, class_1_new_samples], ignore_index=True)\n",
    "\n",
    "        if len(class_1_samples) > m:\n",
    "            class_1_samples = class_1_samples.iloc[-m:]  # Giữ lại m mẫu mới nhất\n",
    "        if i + 1 < len(S):\n",
    "            next_block = S[i + 1]\n",
    "            class_1_samples_df = class_1_samples\n",
    "            S[i + 1] = pd.concat([next_block, class_1_samples_df], ignore_index=True)\n",
    "        block_predictions = []\n",
    "        X = Bi.iloc[:, :-1] \n",
    "        y = Bi.iloc[:, -1]   \n",
    "        Ci = train_random_forest_classifier(X, y)\n",
    "        C.append(Ci)\n",
    "        if len(C) < k:\n",
    "            continue\n",
    "        Bi_1 = S[i + 1]\n",
    "        y = Bi_1.iloc[:, -1]\n",
    "        for index, row in Bi_1.iterrows():\n",
    "            sample = pd.DataFrame([row[:-1]], columns=Bi.columns[:-1])\n",
    "            anpha = (1500 / len(Bi)) * 0.2\n",
    "            selected_classifiers = adaptive_ensemble_size(C, sample, unique_labels, anpha)\n",
    "            pre_sample = tendency_prediction(selected_classifiers, unique_labels)\n",
    "            block_predictions.append(pre_sample)\n",
    "        pre.append(block_predictions)\n",
    "        true_labels.append(list(y))\n",
    "    return C, pre, true_labels\n",
    "C, pre, true_labels = process_data_stream(S, m, k, unique_labels)\n",
    "all_predictions = [pred for block in pre for pred in block]  # Tất cả dự đoán\n",
    "all_true_labels = [label for block in true_labels for label in block]  # Tất cả nhãn đúng\n",
    "\n",
    "# Tính toán chỉ số tổng\n",
    "if len(all_predictions) > 0 and len(all_true_labels) > 0:\n",
    "    precision = precision_score(all_true_labels, all_predictions, average='binary', pos_label=1)\n",
    "    recall = recall_score(all_true_labels, all_predictions, average='binary', pos_label=1)\n",
    "    f1 = f1_score(all_true_labels, all_predictions, average='binary', pos_label=1)\n",
    "    accuracy = accuracy_score(all_true_labels, all_predictions)\n",
    "    \n",
    "    print(\"Total Metrics:\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall: {recall:.4f}\")\n",
    "\n",
    "    print(f\"  F1 Score: {f1:.4f}\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "else:\n",
    "    print(\"No predictions or true labels available to compute metrics.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
